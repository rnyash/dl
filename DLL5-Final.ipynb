{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d3af9c-d510-461e-8465-65750f4b0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: libraries import\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Lambda, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129cf671-48e2-4f7a-a19d-95877243ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised. Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and Transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d80a306-e8f0-48b7-9678-8604e13d50b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised. Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and Transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96072c0b-6bbd-4cf5-84d4-1fde261be1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "word2idx = tokenizer.word_index\n",
    "vocab_size = len(word2idx) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b93d14-349c-49b8-bcec-a7909d4d5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b89fb4b-faa6-497d-84be-b4f61b9e811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "window = 2  # context words around target word\n",
    "for i, target in enumerate(seq):\n",
    "    for j in range(max(0, i - window), min(len(seq), i + window + 1)):\n",
    "        if i != j:\n",
    "            pairs.append((seq[j], target))\n",
    "\n",
    "contexts = np.array([x[0] for x in pairs])\n",
    "targets = np.array([x[1] for x in pairs])\n",
    "targets = to_categorical(targets, vocab_size)  # target words one-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd39ccd-1f3c-4ad9-8572-9617654bbcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rahul\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create CBOW Model\n",
    "input_Layer = Input(shape=(1,))\n",
    "# Embedding(input_dim, output_dim, input_length)\n",
    "embedding_Layer = Embedding(vocab_size, 8, input_length=1, name=\"embedding\")(input_Layer)\n",
    "x = Lambda(lambda x: K.mean(x, axis=1))(embedding_Layer)\n",
    "output_Layer = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_Layer, outputs=output_Layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2645040a-e4eb-481d-ad40-01fcc4c21ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.3161\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3104 \n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3053 \n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3001 \n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2948 \n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2897 \n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2839 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2782 \n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2719  \n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2655 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20f3b9842f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Model training\n",
    "model.fit(contexts, targets, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f433b488-0c61-4c2c-b3e7-d7f21b28bebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\n",
      " Context word: 'artificial'\n",
      "Predicted Target word: 'networks'\n"
     ]
    }
   ],
   "source": [
    "# Testing prediction on a context word\n",
    "test_word = \"artificial\"\n",
    "test_idx = np.array([[word2idx[test_word]]])\n",
    "pred = model.predict(test_idx)\n",
    "predicted_idx = np.argmax(pred)\n",
    "\n",
    "for w, i in word2idx.items():\n",
    "    if i == predicted_idx:\n",
    "        predicted_word = w\n",
    "        break\n",
    "\n",
    "print(f\"\\n Context word: '{test_word}'\")\n",
    "print(f\"Predicted Target word: '{predicted_word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33b7db-a7cb-4fe7-bb65-092e2b3baef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
